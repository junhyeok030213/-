># 지역성의 원리
## 프로그램은 언제든지 주소 공간의 작은 부분에 액세스한다.  (지역성, 국지성, 국부성)
## 시간적 지역성
- 최근에 액세스한 항목은 곧 다시 액세스될 가능성이 높다.
- 예를 들어 루프의 명령어
## 공간의 지역성
- 최근에 접근한 항목 근처에 있는 항목은 곧 접근될 가능성이 높다.
- 예를 들어, 순차적 명령어 액세스, 배열 데이터

># 지역성을 활용하다
## 메모리 계층
## 모든 것을 디스크에 저장
## 최근에 액세스한(및 근처의) 항목을 디스크에서 더 작은 DRAM 메모리로 복사한다.
- 메인 메모리
## 최근에 액세스한(그리고 근처에 있는) 항목을 DRAM에서 더 작은 SRAM 메모리로 복사한다.
- CPU에 연결된 캐시 메모리

># 메모리 계층 수준
<img width="296" alt="스크린샷 2024-06-10 오후 2 59 24" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/4cb04216-8a85-4504-a8e2-1e2cf23139cc">

## 블록(일명 라인): 복사 단위
- 여러 단어일 수 있음
## 접근된 데이터가 다음 위치에 있는 경우 상위 레벨
- Hit: 상위레벨에서 접속의 만족됨

  -> 적중률: 조회수/접속수

## 접근한 데이터가 없는 경우
- Miss: 하위 레벨에서 복사된 블록

  -> 소요시간: 미스 페널티

  -> 미스비율: 미스/액세스 = 1 - 적중률

- 그러면 접근된 데이터는 상위에서 공급된다.

># 메모리 기술
## 정적 RAM(SRAM)
- 0.5ns - 2.5ns, GB당 $500 - $1,000
## 동적 RAM(DRAM)
- 40ns - 70ns, GB당 $3 - $6
## 플래시 메모리
- 5μs - 50μs, GB당 $0.06 - $0.12
## 자기 디스크
- 5ms - 20ms, GB당 $0.01 - $0.02
## 이상적인 메모리
- SRAM의 액세스 시간
- 디스크 용량 및 비용/GB

># DRAM 기술
## 커패시터에 전하로 저장된 데이터
- 전하에 접근하는데 사용되는 단일 트랜지스터
- 주기적으로 새로 고쳐야 함

  -> 내용을 읽고 다시 쓰기

  -> DRAM "행"에서 수행됨

<img width="747" alt="스크린샷 2024-06-10 오후 3 10 29" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/a49c3071-09fa-4916-8d19-b96989c34a10">

># 고급 DRAM 구성
## DRAM의 비트는 직사각형 배열로 구성된다.
- DRAM은 전체 행에 액세스한다.
- 버스트 모드: 대기 시간을 줄이면서 연속적인 단어 제공
## 이중 데이터 전송률(DDR) DRAM
- 상승 및 하강 클럭 에지에서 전송
## 쿼드 데이터 속도(QDR) DRAM
- 별도의 DDR 입력 및 출력

># DRAM 세대
<img width="771" alt="스크린샷 2024-06-10 오후 3 13 10" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/bd23ae8b-b6a0-452b-8dfa-fe65f2f99b31">

># DRAM 성능 요소
## 행 버퍼
- 여러 단어를 동시에 읽고 새로 고칠 수 있다.
## 동기식 DRAM
- 각 주소를 보낼 필요 없이 연속적인 액세스를 허용한다.
- 대역폭 향상
## DRAM 뱅킹
- 여러 DRAM에 대한 동시 액세스 허용
- 대역폭 향상

># 메모리 대역폭 늘리기
<img width="730" alt="스크린샷 2024-06-10 오후 3 15 51" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/984d3122-b2bb-40da-8c51-4f5744e393c0">

## 4워드 와이드 메몰 사용
- 미스 페널티 = 1 + 15 + 1 = 17 버스 사이클
- 대역폭 = 16바이트/17사이클 = 0.94 B/cycle
## 4 뱅크 인터리브 메모리
- 미스 페털티 = 1 + 15 + 4 x 1 = 20 버스 사이클
- 대역폭 = 16바이트/20사이클 = 0.8 B/cycle

># 플래시 메모리(스토리지)
## 불휘발성 반도체 메모리(스토리지)
- 디스크보다 100배 - 1000배 빠름
- 더 작고, 더 낮은 전력,더 견고함
- 하지만 $/GB(디스크와 DRAM 간)가 더 높다.
<img width="547" alt="스크린샷 2024-06-10 오후 3 20 25" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/e3a9b072-ec81-42a4-8454-a9f360f246e3">

># 플래시 메모리 유형
## 전기적으로 지울 수 있는 프로그래밍 가능 ROM(EEPROM)의 일종
## NOR 플래시: NOR 게이트와 같은 비트 셀
- 무작위 읽기/쓰기 액세스
- 임베디드 시스템의 명령어 메모리에 사용된다.
## NAND 플래시: NAND 게이트와 같은 비트 셀
- 밀도(비트/영역)는 높지만 한 번에 블록 액세스 가능
- GB당 가격이 저렴함
- USB 키, 미디어 저장 등에 사용된다
## 플래시 비트는 1000~100,000번의 액세스 후에 마모된다.
- 직접 RAM 또는 디스크 교체에 적합하지 않음
- 웨어 레벨링: 데이터를 덜 사용되는 블록으로 다시 매핑

># 디스크 저장소
## 비휘발성, 회전식 자기 스토리지
<img width="771" alt="스크린샷 2024-06-10 오후 3 24 52" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/9e80469a-5e47-49c3-bdea-adb0a06cfedc">

># 디스크 섹터 및 액세스
## 각 부문별 기록
- 섹터 ID
- 데이터(512바이트, 4096바이트 제안)
- 오류 정정 코드(ECC)

  -> 결함을 숨기고 오류를 기록하는 데 사용된다.

- 동기화 필드 및 격차

## 특정 부문에 대한 접근에는 다음이 포함된다.
- 다른 액세스가 보류 중인 경우 대기열 지연
- 탐색: 머리를 움직인다.
- 회전 지연 시간

  -> 평균 지연 시간은 디스크의 절번 정도이다.(0.5회전에 소요되는 시간)

- 데이터 전송
- 컨트롤러 오버헤드

># 디스크 액세스 예
## Given
- 512 B 섹터, 15,000rpm, 4ms 평균 탐색 시간, 100MB/s 전송 속도, 0.2ms 컨트롤러 오버헤드, 유휴 디스크
## 평균 읽기 시간
- 4ms 탐색 시간 + 2ms(= (1/2) / (15,000/60)) 회전 대기 시간 + 0.005ms(= 512 B / 100MB/s) 전송 시간 + 0.2ms 컨트롤러 지연 = 6.2ms
## 실제 평균 탐색 시간이 1ms 라면,
- 평균 읽기 시간 = 3.2ms

># 디스크 성능 문제
## 제조업체는 평균 탐색 시간을 인용한다.
- 가능한 모든 탐색을 기반으로 함
- 지역성과 OS 스케줄링으로 인해 실제 평균 탐색 시간이 더 짧아진다.
## 스마트 디스크 컨트롤러
- SCSI(소형 컴퓨터 시스템 인터페이스), ATA(첨단 기술 부착), SATA(직렬 ATA)
## 디스크 드라이브에는 캐시가 포함되어 있다.
- 액세스가 예상되는 프리패치 섹터
- 탐색 및 회전 지연 방지

># 캐시 메모리
## 캐시 메모리
- CPU에 가장 가까운 메모리 계층 구조 수준
<img width="745" alt="스크린샷 2024-06-10 오후 3 42 17" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/81341b0a-cab3-4e4e-851b-75741ff80c34">

># 직접 매핑된 캐시
## 주소로 결정되는 위치
## 직접 매핑: 단 하나의 선택
- (블록 주소) 모듈로 (캐시 내 #Blocks)

<img width="465" alt="스크린샷 2024-06-10 오후 3 45 08" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/8e524267-72da-4fd2-b738-8c30292a415f">

># 태그 및 유효한 비트
## 캐시 위치에 어떤 특정 블록이 저장되어 있는지 어떻게 알 수 있나?
- 블록 주소와 데이터를 저장한다.
- 실제로는 상위 비트만 필요하다.
- 태그를 호출했다.
## 특정 위치에 데이터가 없으면 어떻게 되는가?
- 유효한 비트: 1 = 존재, 0 = 존재하지 않음
- 처음에는 0

># 캐시 예
## 8블록, 1워드/블록, 직접 매핑
## 초기 상태
<img width="492" alt="스크린샷 2024-06-10 오후 3 47 36" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/63ee2364-3814-45c4-b640-6111a5011b29">

<img width="428" alt="스크린샷 2024-06-10 오후 3 48 09" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/af14ed08-355e-4de5-b1f4-505b4389b5a2">

<img width="424" alt="스크린샷 2024-06-10 오후 3 48 23" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/40303546-018d-4ba4-b35a-7ad8cd64ff1a">

<img width="425" alt="스크린샷 2024-06-10 오후 3 48 35" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/9582d304-758d-4cac-a4b4-7f96e88a3c4e">

<img width="422" alt="스크린샷 2024-06-10 오후 3 48 48" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/21e77d61-0b87-4cc8-848e-5c5d6a6b3455">

<img width="427" alt="스크린샷 2024-06-10 오후 3 49 04" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/1913e99f-ef88-4396-a3e1-7635a5850586">

># 주소 세분화
<img width="368" alt="스크린샷 2024-06-10 오후 3 49 54" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/f57b190e-18ec-463e-9d2f-859ba7e841d5">

># 예: 더 큰 블록 크기
## 64개 블록, 16바이트/불록
- 주소 1200은 어떤 블록 번호에 매핑되는가?
## 블록 주소 - ⎣주소/블록크기⎦ = ⎣1200/16⎦ = 75
## 블록 번호 = (블록 주소) modulo (#블록) = 75 modulo 64 = 11
<img width="379" alt="스크린샷 2024-06-10 오후 3 56 51" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/1fe30ef6-4d6f-4cd0-9a97-fdb8231864d7">

># 블록 크기 고려 사항
## 블록이 클수록 미스 비율이 줄어든다.
- 공간적 지역성으로 이냏
## 하지만 고정된 크기의 캐시에서는
- 더 큰 블록 => 더 적은 수

  -> 경쟁 심화 => 미스율 증가

- 더 큰 블록 => 오염

## 미스 페널티가 커짐
- 감소된 미스 비율의 이점을 무시할 수 있다.
- 중요한 단어 우선 및 조기 재시작이 도움을 될 수 있다.

># 캐시 미스
## 캐시 적중 시 CPU는 정상적으로 진행된다.
## 캐시 미스 시
- CPU 파이프라인 정재
- 다음 계층 구조에서 블록을 가져온다.
- 명령어 캐시 미스

  -> 재시작 명령 가져오기

- 데이터 캐시 미스

  -> 완전한 데이터 액세스

># 미스의 원인
## 강제 실패(콜드 스타트 실패라고도 함)
- 블록에 대한 첫 번째 액세스
## 용량 누락
- 제한된 캐시 크기로 인해
- 교체된 블록은 나중에 다시 액세스 된다.
## 충돌 미스
- 완전 연관 캐시가 아닌 경우
- 세트 참가 경쟁으로 인해
- 동일한 전체 크기의 완전 연관 캐시에서는 발생하지 않는다.

># 연속 기입
## 데이터 쓰기 적중 시 캐시의 블록을 업데이트할 수 있다.
- 하지만 그러면 캐시와 메모리가 일치하지 않게 된다.
## Write through: 메모리도 업데이트
## 하지만 쓰기 시간이 더 오래 걸린다.
- 예를 들어 기본 CPI = 1 이면 명령의 10%가 저장되고 메모리에 쓰는 데 100사이클이 걸린다.

  -> 유효 CPI = 1 + 0.1 x 100 = 11

## 해결책: 쓰기 버퍼
- 메모리에 기록되기를 기다리는 데이터를 보관합니다.
- CPU는 즉시 계속된다.

  -> 쓰기 버퍼가 이미 가득 찬 경우에만 쓰기가 중단된다.

># 다시 쓰기
## 대안: 데이터 쓰기 적중 시 캐시의 블록을 업데이트 하기만 하면 된다.
- 각 블록이 더러운지 추적하라.
## 더러운 블록을 고체할 때
- 다시 기억에 적어보아라
- 쓰기 버퍼를 사용하여 '블록 교체'를 먼저 읽을 수 있다.

># 쓰기 할당
## 쓰기 오류가 발생하면 어떻게 되나?
## Write-through의 대안
- 실패 시 할당: 블록을 가져온다.
- Write around: 블럭을 가져오지 않음

  -> 프로그램은 종종 블록을 읽기 전에 전체 블록을 작성하기 때문에 (예: 초기화)

## 후기입인 경우
- 일반적으로 블록을 가져온다.

># 예: Intrinsity FastMATH
## 내장형 MIPS 프로세서
- 12단계 파이프라인
- 각 사이클의 명령 및 데이터 액세스
## 분할 캐시: I-캐시와 D-캐시를 분리
- 각 16KB: 256블록 x 16워드/블록
- D-캐시: 연속 기입 또는 후기입
## SPEC CPU2000 미스 비율
- 아이캐시: 0.4%
- D-캐시: 11.4%
- 가중평균: 3.2%

<img width="556" alt="스크린샷 2024-06-10 오후 4 12 57" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/5aef064c-c09a-4a26-8761-b50257993f38">

># 캐시를 지원하는 메인 메모리
## 주 메모리로 DRAM 사용
- 고정 너비(예: 1워드)
- 고정 폭 믈록 버스로 연결됨

  -> 버스 클럭은 일반적으로 CPU 클럭보다 느립니다.

## 캐시 블록 읽기 예시
- 주소 전송을 위한 1 버스 사이클
- DRAM 액세스당 버스 사이클 15개
- 데이터 전송당 버스 사이클 1개

## 4워드 블록의 경우 1워드 폭 DRAM
- 미스 페널티 = 1 + 4 x 15 + 4 x 1   = 64 사이클
- 대역폭 = 16바이트/65사이클 = 0.25 B/cycle

># 캐시 성능 측정
## CPU 시간의 구성요소
- 프로그램 실행주기

  -> 캐시 적중 시간 포함

- 메모리 정지 주기

  -> ㅈ로 캐시 미스로 인해 발생

## 가정을 단순화 하면 다음과 같다.  
<img width="354" alt="스크린샷 2024-06-10 오후 4 21 53" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/d9b16b72-e93c-4c06-af4b-7252028ab49a">

># 캐시 성능 예
## Given
- I-캐시 실패율 = 2%
- D-캐시 누락률 = 4%
- 미스 페널티 = 100 사이클
- 기본 CPI(이상적인 캐시) = 2
- 로드 및 저장은 명령어의 36%이다.
## 명령어당 미스 사이클
- I-캐시: 0.02 x 100 = 2
- D-캐시: 0.36 x 0.04 x 100 =1.44
## 실제 CPI = 2 + 2 + 1.44 = 5.44
- 이상적인 CPU는 5.44/2 = 2.72배 빠르다.

># 평균 액세스 시간
## 적중 시간도 성능에 중요하다.
## 평균 메모리 액세스 시간(AMAT)
- AMAT = 적중 시간 + 미스 비율 x 미스 페널티
## 예
- 1ns 클록의 CPU, 적중시간 = 1사이클, 미스 페널티 = 20사이클 I-캐시 미스 비율 = 5%
- AMAT = 1 + 0.05 x 20 = 2ns

  -> 명령당 2사이클

># 성능 요약
## CPU 성능이 향상되면
- 미스 페널티가 더욱 중요해진다.
## 기본 CPI 감소
- 메모리 정지에 더 많은 시간이 소요된다.
## 클럭 속도 증가
- 메모리 정지는 더 많은 CPU 주기를 차지한다.
## 시스템 성능을 평가할 때 캐시 동작을 무시할 수 없다.

># 연관 캐시
## 완전 연관
- 특정 블록이 이 모든 캐시 항목에 들어갈 수 있도록 허용
- 모든 항목을 한 번에 검색해야 한다.
- 항목당 비교기(비쌈)
## n방향 집합 연관
- 각 세트에는 n개의 항목이 포함된다.
- 블록 번호는 세트를 결정한다.

  -> (블록 번호) modulo (캐시에 있는 #sets)

- 주어진 세트의 모든 항목을 한 번에 검색
- n개의 비교기(저렴한 비용)

># 연관 캐시 예제
<img width="651" alt="스크린샷 2024-06-10 오후 4 33 16" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/e29d7c40-d953-468f-8dce-65841eda17e3">

># 연관성 스펙트럼
## 8개의 항목이 있는 캐시의 경우
<img width="507" alt="스크린샷 2024-06-10 오후 4 33 54" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/1a7fa255-e838-41d0-a0e1-5d5d0d614763">

># 연관성 예
## 4블록 캐시 비교
- 직접 매핑, 양방향 세트 연관, 완전 연관
- 블록 액세스 순서: 0, 8, 0, 6, 8
## 직접 매핑됨
<img width="561" alt="스크린샷 2024-06-10 오후 4 35 19" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/10c8a3df-08e2-4dac-8b21-23de1fcd86f1">

## 양방향 세트 연관
<img width="561" alt="스크린샷 2024-06-10 오후 4 36 59" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/b17d86f5-fde0-4cc1-a40f-388b6a5f34ae">

## 완전 연관
<img width="557" alt="스크린샷 2024-06-10 오후 4 37 11" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/e8812896-bf74-457f-abaa-d19f0fb537bc">

># 얼마나 많은 연관성이 있나?
## 연관성이 증가하면 미스 비율이 감소한다.
- 하지만 수익이 감소하면서 감소한다.
## SPEC CPU2000 벤치마크에 대한 64KB D 캐시 및 16워드 블록을 갖춘 시스템의 시뮬레이션(미스 비율)
- 단방향(직접 매핑): 10.3%
- 양방향: 8.6%
- 4방향: 8.3%
- 8방향: 8.1%

># 4-Way 세트 연관 캐시 구성
<img width="462" alt="스크린샷 2024-06-10 오후 4 40 23" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/cb9aecd8-4181-46e6-9457-480b2a64fd4d">

># 교체 정책
## 직접 매핑: 선택 사항 없음
## 연관 설정
- 유효하지 않은 항목이 있는 경우 이를 선호한다.
- 그렇지 않으면 세트의 항목 중에서 선택한다.
## 가장 최근에 사용됨(LRU)
- 가장 오랫동안 사용하지 않은 것을 선택하라.

  -> 2-way는 간단하고, 4-way는 관리하기 쉽고, 그 이상은 너무 어렵다.

## 무작위의
- 높은 연관성을 위해 LRU와 거의 동일한 성능 제공

># 다단계 캐시
## CPU에 연결된 기본 캐시
- 작지만 빠르다
## 레벨 2 캐시 서비스가 기본 캐시에서 누락되었다.
- 메인 메모리보다 크고 느리지만 여전히 빠르다.
## 주 메모리 서비스 L-2 캐시가 누락되었다.
## 일부 고급 시스템에는 L-3 캐시가 포함되어 있다.

># 다중 레벨 캐시의 예
## Given
- CPU 기본 CPI = 1, 클록 속도 = 4GHz
- 미스 비율/명령어 = 2%
- 메인 메모리 액세스 시간 = 100ns

## 기본 캐시만 사용
- 미스 페널티 = 100ns/0.25ns = 400 사이클
- 유효 CPI = 1 + 0.02 x 400 = 9

># 다중 레벨 캐시 예(cont'd)
## 이제 L-2 캐시를 추가하시오
- 액세스 시간 = 5ns
- 메인 메모리에 대한 글로벌 미스 비율 = 0.5%
## L-2 히트로 인한 1차 실패
- 페널티 = 5ns/0.25ns = 20사이클
## L-2 미스를 포함한 1차 미스
- 추가 페널티 = 400 사이클
## CPI = 1 + 0.02 x 20 + 0.05 x 400 = 3.4
## 성능 비율 = 9/3.4 = 2.6

># 다중 레벨 캐시 고려사항
## 기본 캐시
- 최소 적중 시간에 집중
## L-2 캐시
- 메인 메모리 액세스를 피하기 위해 낮은 미스 비율에 집중
- 적중 시간은 전체적인 영향이 적다.
## 결과
- L-1 캐시는 일반적으로 작다.
- L-1 블록 크기는 L-2 블록 크기보다 작다.

># 고급 CPU와의 상호 작용
## 순서가 잘못된 CPU는 캐시 누락 중에 명령을 실행할 수 있다.
- 보류 중인 저장소는 로드/저장 단위에 유지된다.
- 예약 스테이션에서 종속 지시 대기

  -> 독립지시 계속

## 누락의 영향은 프로그램 데이터 흐름에 따라 다르다.
- 분석하기가 훨씬 더 어렵다.
- 시스템 시뮬레이션 사용

># 소프트웨어와의 상호 작용
## Miss는 메모리 액세스 패턴에 따라 달라진다.
- 알고리즘 동작
- 메모리 액세스를 위한 컴파일러 최적화

<img width="235" alt="스크린샷 2024-06-10 오후 4 56 28" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/052a6f1e-3a23-4514-9678-0e5cb76dadfd">

># 믿을 수 있음
<img width="1004" alt="스크린샷 2024-06-10 오후 4 57 55" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/63d7c105-09bb-41f6-9db4-4d24ac0f19e9">

># 신뢰성 측정
<img width="481" alt="스크린샷 2024-06-10 오후 4 58 44" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/ad69a349-00f5-42bb-872f-4af05d1d008f">

## 신뢰성: 평균 고장 시간(MTTF)
## 서비스 중단: 평균 수리 시간(MTTR)
## 실패 사이의 평균 시간
- MTBF = MTTF + MTTR
## 가용성 = MTTF / (MTTF + MTTR)
## 가용성 향상
- MTTF 증가: 결함 방지, 결함 허용, 결함 예측
- MTTR 감소: 진단 및 수리를 위한 향상된 도구 및 프로세스

># 9가지 가용성
## 우리는 가용성이 매우 높기를 원한다.
## 한 가지 약어로는 연간 "9개의 가용성" 수를 인용하는 것이다.
## 1년 365일(365 x 24 x 60 = 526,000분)을 가정하면 약식은 다음과 같다.
<img width="418" alt="스크린샷 2024-06-10 오후 5 04 51" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/cfb874ed-d8ba-45a5-baeb-e80413c776f0">

## 오늘날 매우 좋은 인터넷 서비스는 4~5개의 가용성을 제공합니다
- 5 nines는 1년에 5분의 수리를 의미하며, 이는 기억 보조 장치입니다.

># 해밍 SEC/DED
## 해밍 거리
- 두 비트 패턴 간의 서로 다른 비트 수 예:
- 예) d(011011, 001111) = 2
## 최소 해밍 거리 d_min
- 비트 패턴 집합에서 임의의 두 비트 패턴 간에 다른 최소 비트 수
## 최소 해밍 거리 = 2는 단일 비트 오류 감지를 제공한다.
- 예를 들어 패리티 코드(본문에서는 패리티도 있음)
## 최소 해밍 거리 = 3은 단일 오류 수정(SEC) 및 이중 오류 감지(DED)를 제공한다.

># SEC 인코딩
## 해밍 코드를 계산하려면 다음을 수행하라
- 왼쪽(비트 위치)의 1부터 비트 번호를 매긴다.
- 거듭제곱 2인 모든 비트 위치는 패리티 비트(1,2,4,8)이다.
- 각 패리티 비트는 특정 데이터 비트(여기서는 패리티도 포함)을 확인한다. (각 데이터 비트는 두 개 이상의 패리티 비트로 구성된다.)
<img width="188" alt="스크린샷 2024-06-10 오후 9 20 48" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/a4218131-54ac-4b7c-86ea-f545364efeb0">

<img width="505" alt="스크린샷 2024-06-10 오후 9 20 31" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/eb9bb544-34af-4e78-b5fd-1bea0218c1fe">

># SEC 디코딩
## 패리티 비트 값은 어떤 비트에 오류가 있는지 나타낸다.
## 12비트 코드에 대한 인코딩 절차의 번호 매기기 사용
- 패리티 비트: p8, p4, p2, p1
- 데이터 비트: d8, d7, d6, d5, d4, d3, d2, d1
## 패리티 자체를 포함하여 4개의 패리티 비트(p8, p4, p2, p1) 계산
- 패리티 비트 = 0000(0_(10))은 오류가 없음을 나타낸다.
- 패리티 비트 = 1010(10_(10))은 비트 10_(10) (d6)이 반전되었음을 나타낸다,

  -> 비트 위치는 이전 슬라이드를 참조하여라.

## 예
- 인코딩: 데이터 1001 1010_(2) -> 12비트 패턴 011100101010
<img width="578" alt="스크린샷 2024-06-10 오후 9 27 21" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/87b9f850-d681-4fe2-a445-7cabbafb32c5">

- 디코딩: 오류가 없으면 패리티 비트는 0000이다. d6에 에러가 발생하면 12비트 패턴 011100101110 -> 패리티 비트는 1010이다.

># 가상 머신
## 호스트 컴퓨터는 게스트 운영 체제와 시스템 리소스를 에뮬레이트한다.
- 여러 손님의 격리 개선
- 보안 및 안정성 문제 방지
- 특히 클라우드 컴퓨팅의 경우 리소스 공유를 지원한다.

  -> VM을 사용하면 여러 OS가 모두 하드웨어 리소스를 공유한다.

## 가상화는 성능에 어느 정도 영향을 미친다.
- 최신 고성능 컴퓨터로 가능
## 예
- IBM VM/370(1970년대 기술!)
- VMWare
- 마이크로소프트 가상 PC
- 아마존 웹 서비스(AWS)

># 가상 머신 모니터
## 가상 자원을 물리적 자원(메모리, I/O 장치, CPU)에 매핑한다.
- VMM은 VM을 지원하는 소프트웨어이다.
- VMM은 기존 OS보다 훨씬 작다.
## 게스트 코드는 사용자 모드의 기본 컴퓨터에서 실행된다.
- 권한 있는 명령 및 보호된 리소스에 대한 액세스에 대해 VMM을 트랩한다.
## 게스트 OS는 호스트 OS와 다를 수 있다.
## VMM은 실제 I/O 장치를 처리한다.
- 게스트용 일반 가상 I/O 장치를 에뮬레이트한다.

># 가상 머신 모니터
## 네이티브 머신에서 타이머 인터럽트 시
- OS는 현재 프로세스를 일시 중지하고, 인터럽트를 처리하고, 다음 프로세스를 선택하고 재개한다.
## 가상 머신 모니터 사용
- VMM은 현재 VM을 일시 중단하고, 인터럽트를 처리하고, 다음 VM을 선택하고 재개한다.

># 가상 메모리
## 메인 메모리를 보조(디스크) 스토리지용 "캐시"로 사용
- CPU 하드웨어와 운영체제(OS)가 공동으로 관리한다.
## 프로그램은 주 메모리를 공유한다.
- 각각은 자주 사용되는 코드와 데이터를 보관하는 개인 가상 주소 공간을 얻는다.
- 다른 프로그램으로부터 보호됨
## CPU와 OS는 가상 주소를 물리적 주소로 변환한다.
- VM "블록"을 페이지라고 한다.
- VM 변환 "miss"를 페이지 오류라고 한다.

># 주소 번역
## 고정 크기 페이지(예: 4K)
<img width="546" alt="스크린샷 2024-06-10 오후 9 39 07" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/9f8a015e-21ca-42b3-81d0-fa794c75653c">

># 페이지 오류 페널티
## 페이지 결함이 발생하면 페이지를 디스크에서 가져와야 한다.
- 수백만 개의 클럭 사이클이 소요된다.
- OS 코드로 처리
## 페이지 오류 비율을 최소화하려고 노력한다.
- 완전 연관 배치
- 스마트 교체 알고리즘

># 페이지 테이블
## 배치 정보를 저장한다.
- 가상 페이지 번호로 인덱싱된 페이지 테이블 항목(PTE) 배열
- CPU의 페이지 테이블 레지스터는 물리적 메모리의 페이지 테이블을 가리킨다.
## 페이지가 메모리에 존재하는 경우
- PTE는 실제 페이지 번호를 저장한다.
- 기타 상태 비트(참조됨, 더티 등)
## 페이지가 존재하지 않는 경우
- PTE는 디스크의 스왑 공간 위치를 참조할 수 있다.

># 페이지 테이블을 사용한 번역
<img width="615" alt="스크린샷 2024-06-10 오후 9 43 16" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/67b625d5-b510-4750-9283-5347d29ad6d7">

># 페이지를 저장소에 매핑
<img width="481" alt="스크린샷 2024-06-10 오후 9 43 46" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/79c59982-c00e-4c9a-b7fb-4078f490f080">

># 교체 및 쓰기
## 페이지 오류 비율을 줄이기 위해 LRU(최근 사용) 교체가 선호된다.
- PTE의 참조 비트(사용 비트라고도 함)는 페이지 액세스 시 1로 설정된다.
- OS에 의해 주기적으로 0으로 지워짐
- 참조 비트 = 0인 페이지는 최근에 사용되지 않는다.
## 디스크 쓰기에는 수백만 번의 주기가 걸린다.
- 개별 위치가 아닌 한번에 차단
- 끝까지 쓰는 것은 비현실적이다.
- 후기입 사용
- 페이지가 기록될 때 PTE의 더티 비트가 설정된다.

># TLB를 사용한 빠른 번역
## 주소 변환에는 추가 메모리 참조가 필요한 것으로 보인다.
- PTE에 액세스하기 위한 하나
- 그런 다음 실제 메모리 액세스
## 그러나 페이지 테이블에 대한 액세스는 지역성이 좋다.
- 따라서 CPU 내에서 빠른 PTE 캐시를 사용한다.
- TLB(번역 참조 버퍼)라고 한다.
- 일반적인 값:

  -> 16~512 PTE, 적중 시 0.5~1사이클, 미스 시 10~100사이클, 미스 비율 0.01%~1%

- 누락은 하드웨어나 소프트웨어로 처리될 수 있다.

># TLB를 이용한 고속 번역
<img width="518" alt="스크린샷 2024-06-10 오후 9 50 48" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/aefa0f60-ab70-43a3-a119-aca989f6f518">

># TLB 미스
## 페이지가 메모리에 있는 경우
- 메모리에서 PTE를 로드하고 다시 시도한다.
- 하드웨어에서 처리 가능

  -> 더 복잡한 페이지 테이블 구조로 인해 복잡해질 수 있음

- 또는 소프트웨어에서

  -> 최적화된 핸들러로 특별한 예외 발생

## 페이지가 메모리에 없는 경우(페이지 폴트)
- OS는 페이지 가져오기 및 페이지 테이블 업데이트를 처리한다.
- 그런 다음 오류가 발생한 명령을 다시 시작한다.

># TLB 미스 핸들러
## TLB 미스는 다음을 나타낸다.
- 페이지가 있지만 PTE는 TLB에 없는다.
- 페이지가 존재하지 않는다.
## 대상 레지스터를 덮어쓰기 전에 TLB 미스를 인식해야 한다.
- 예외 발생
## 핸들러는 PTE를 메모리에서 TLB로 복사한다.
- 그런 다음 지시를 다시 시작한다.
- 페이지가 없으면 페이지 폴트가 발생한다.

># 페이지 오류 처리기
## 오류가 있는 가상 주소를 사용하여 PTE 찾기
## 디스크에서 페이지 찾기
## 교체할 페이지 선택
- 더러워지면 먼저 디스크에 쓴다.
## 페이지를 메모리로 읽고 페이지 테이블을 업데이트한다.
## 프로세스를 다시 실행 가능하게 만들기
- 오류가 발생한 명령에서 다시 시작

># TLB와 캐시 상호 작용
<img width="344" alt="스크린샷 2024-06-10 오후 9 57 39" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/54c53add-061c-40f6-a740-af74754e45cd">

## 캐시 태그가 물리적 주소를 사용하는 경우
- 캐시 조회 전 번역 필요
## 대안: 가상 주소 태그 사용
- 앨리어싱으로 인한 합병증

  -> 공유된 물리적 주소에 대해 서로 다른 가상 주소

># 메모리 보호
## 다양한 작업이 가상 주소 공간의 일부를 공유할 수 있다.
- 그러나 잘못된 액세스로부터 보호해야 함
- OS 지원 필요
## OS 보호를 위한 하드에어 지원
- 권한 있는 감독자 모드(커널 모드라고도 함)
- 특권 지침
- 페이지 테이블 및 기타 상태 정보는 감독자 모드에서만 액세스 가능
- 시스템 호출 예외(예: MIPS의 syscall)

># 멀티레벨 온칩 캐시
<img width="428" alt="스크린샷 2024-06-10 오후 10 01 03" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/55bafe7f-23cd-4a19-aeca-f63ed6fcf175">

># 주소 변환 및 TLB 조직
<img width="508" alt="스크린샷 2024-06-10 오후 10 01 33" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/f0a5db8a-a5f6-47da-91be-e3d382755586">

># 여러 문제 지원
## 두 가지 모두 뱅크 충돌이 없다는 가정 하에 주기당 다중 액세스를 허용하는 다중 뱅크 캐시를 가지고 있다.
## Core i7 캐시 최적화
- 요청한 단어를 먼저 반환
- 비차단 캐시

  -> 미스 언더 히트

  -> 미스 언더 미스

- 데이터 미리 가져오기

># 부팅 과정
## OS는 어떻게 자체적으로 시작되나?
## OS를 부팅해야 한다.
## CPU는 ROM에서 첫 번째 명령을 읽는다.
- 이것이 부트스트랩이다.
## 부트스트랩은 OS를 대용량 저장소에서 OS 실행이 시작되는 RAM으로 이동하도록 컴퓨터에 지시한다.

># 부팅 프로세스
<img width="602" alt="스크린샷 2024-06-10 오후 10 04 59" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/bd7bfd2b-4e3c-43d8-a4cd-70e535852204">

># 끝 맺는 말
## 빠른 기억은 작고, 큰 기억은 느리다.
- 우리는 정말 빠르고 큰 추억을 원한다 🙁
- 캐싱은 이러한 환상을 제공한다 🙂
## 지역성의 원리
- 프로그램은 메모리 공간의 작은 부분을 자주 사용한다.
## 메모리 계층
- L1 캐시 ↔ L2 캐시 ↔ ... ↔ DRAM 메모리 ↔ 디스크
## 멀티프로세서에는 메모리 시스템 설계가 중요하다. 
