># 지역성의 원리
## 프로그램은 언제든지 주소 공간의 작은 부분에 액세스한다.  (지역성, 국지성, 국부성)
## 시간적 지역성
- 최근에 액세스한 항목은 곧 다시 액세스될 가능성이 높다.
- 예를 들어 루프의 명령어
## 공간의 지역성
- 최근에 접근한 항목 근처에 있는 항목은 곧 접근될 가능성이 높다.
- 예를 들어, 순차적 명령어 액세스, 배열 데이터

># 지역성을 활용하다
## 메모리 계층
## 모든 것을 디스크에 저장
## 최근에 액세스한(및 근처의) 항목을 디스크에서 더 작은 DRAM 메모리로 복사한다.
- 메인 메모리
## 최근에 액세스한(그리고 근처에 있는) 항목을 DRAM에서 더 작은 SRAM 메모리로 복사한다.
- CPU에 연결된 캐시 메모리

># 메모리 계층 수준
<img width="296" alt="스크린샷 2024-06-10 오후 2 59 24" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/4cb04216-8a85-4504-a8e2-1e2cf23139cc">

## 블록(일명 라인): 복사 단위
- 여러 단어일 수 있음
## 접근된 데이터가 다음 위치에 있는 경우 상위 레벨
- Hit: 상위레벨에서 접속의 만족됨

  -> 적중률: 조회수/접속수

## 접근한 데이터가 없는 경우
- Miss: 하위 레벨에서 복사된 블록

  -> 소요시간: 미스 페널티

  -> 미스비율: 미스/액세스 = 1 - 적중률

- 그러면 접근된 데이터는 상위에서 공급된다.

># 메모리 기술
## 정적 RAM(SRAM)
- 0.5ns - 2.5ns, GB당 $500 - $1,000
## 동적 RAM(DRAM)
- 40ns - 70ns, GB당 $3 - $6
## 플래시 메모리
- 5μs - 50μs, GB당 $0.06 - $0.12
## 자기 디스크
- 5ms - 20ms, GB당 $0.01 - $0.02
## 이상적인 메모리
- SRAM의 액세스 시간
- 디스크 용량 및 비용/GB

># DRAM 기술
## 커패시터에 전하로 저장된 데이터
- 전하에 접근하는데 사용되는 단일 트랜지스터
- 주기적으로 새로 고쳐야 함

  -> 내용을 읽고 다시 쓰기

  -> DRAM "행"에서 수행됨

<img width="747" alt="스크린샷 2024-06-10 오후 3 10 29" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/a49c3071-09fa-4916-8d19-b96989c34a10">

># 고급 DRAM 구성
## DRAM의 비트는 직사각형 배열로 구성된다.
- DRAM은 전체 행에 액세스한다.
- 버스트 모드: 대기 시간을 줄이면서 연속적인 단어 제공
## 이중 데이터 전송률(DDR) DRAM
- 상승 및 하강 클럭 에지에서 전송
## 쿼드 데이터 속도(QDR) DRAM
- 별도의 DDR 입력 및 출력

># DRAM 세대
<img width="771" alt="스크린샷 2024-06-10 오후 3 13 10" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/bd23ae8b-b6a0-452b-8dfa-fe65f2f99b31">

># DRAM 성능 요소
## 행 버퍼
- 여러 단어를 동시에 읽고 새로 고칠 수 있다.
## 동기식 DRAM
- 각 주소를 보낼 필요 없이 연속적인 액세스를 허용한다.
- 대역폭 향상
## DRAM 뱅킹
- 여러 DRAM에 대한 동시 액세스 허용
- 대역폭 향상

># 메모리 대역폭 늘리기
<img width="730" alt="스크린샷 2024-06-10 오후 3 15 51" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/984d3122-b2bb-40da-8c51-4f5744e393c0">

## 4워드 와이드 메몰 사용
- 미스 페널티 = 1 + 15 + 1 = 17 버스 사이클
- 대역폭 = 16바이트/17사이클 = 0.94 B/cycle
## 4 뱅크 인터리브 메모리
- 미스 페털티 = 1 + 15 + 4 x 1 = 20 버스 사이클
- 대역폭 = 16바이트/20사이클 = 0.8 B/cycle

># 플래시 메모리(스토리지)
## 불휘발성 반도체 메모리(스토리지)
- 디스크보다 100배 - 1000배 빠름
- 더 작고, 더 낮은 전력,더 견고함
- 하지만 $/GB(디스크와 DRAM 간)가 더 높다.
<img width="547" alt="스크린샷 2024-06-10 오후 3 20 25" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/e3a9b072-ec81-42a4-8454-a9f360f246e3">

># 플래시 메모리 유형
## 전기적으로 지울 수 있는 프로그래밍 가능 ROM(EEPROM)의 일종
## NOR 플래시: NOR 게이트와 같은 비트 셀
- 무작위 읽기/쓰기 액세스
- 임베디드 시스템의 명령어 메모리에 사용된다.
## NAND 플래시: NAND 게이트와 같은 비트 셀
- 밀도(비트/영역)는 높지만 한 번에 블록 액세스 가능
- GB당 가격이 저렴함
- USB 키, 미디어 저장 등에 사용된다
## 플래시 비트는 1000~100,000번의 액세스 후에 마모된다.
- 직접 RAM 또는 디스크 교체에 적합하지 않음
- 웨어 레벨링: 데이터를 덜 사용되는 블록으로 다시 매핑

># 디스크 저장소
## 비휘발성, 회전식 자기 스토리지
<img width="771" alt="스크린샷 2024-06-10 오후 3 24 52" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/9e80469a-5e47-49c3-bdea-adb0a06cfedc">

># 디스크 섹터 및 액세스
## 각 부문별 기록
- 섹터 ID
- 데이터(512바이트, 4096바이트 제안)
- 오류 정정 코드(ECC)

  -> 결함을 숨기고 오류를 기록하는 데 사용된다.

- 동기화 필드 및 격차

## 특정 부문에 대한 접근에는 다음이 포함된다.
- 다른 액세스가 보류 중인 경우 대기열 지연
- 탐색: 머리를 움직인다.
- 회전 지연 시간

  -> 평균 지연 시간은 디스크의 절번 정도이다.(0.5회전에 소요되는 시간)

- 데이터 전송
- 컨트롤러 오버헤드

># 디스크 액세스 예
## Given
- 512 B 섹터, 15,000rpm, 4ms 평균 탐색 시간, 100MB/s 전송 속도, 0.2ms 컨트롤러 오버헤드, 유휴 디스크
## 평균 읽기 시간
- 4ms 탐색 시간 + 2ms(= (1/2) / (15,000/60)) 회전 대기 시간 + 0.005ms(= 512 B / 100MB/s) 전송 시간 + 0.2ms 컨트롤러 지연 = 6.2ms
## 실제 평균 탐색 시간이 1ms 라면,
- 평균 읽기 시간 = 3.2ms

># 디스크 성능 문제
## 제조업체는 평균 탐색 시간을 인용한다.
- 가능한 모든 탐색을 기반으로 함
- 지역성과 OS 스케줄링으로 인해 실제 평균 탐색 시간이 더 짧아진다.
## 스마트 디스크 컨트롤러
- SCSI(소형 컴퓨터 시스템 인터페이스), ATA(첨단 기술 부착), SATA(직렬 ATA)
## 디스크 드라이브에는 캐시가 포함되어 있다.
- 액세스가 예상되는 프리패치 섹터
- 탐색 및 회전 지연 방지

># 캐시 메모리
## 캐시 메모리
- CPU에 가장 가까운 메모리 계층 구조 수준
<img width="745" alt="스크린샷 2024-06-10 오후 3 42 17" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/81341b0a-cab3-4e4e-851b-75741ff80c34">

># 직접 매핑된 캐시
## 주소로 결정되는 위치
## 직접 매핑: 단 하나의 선택
- (블록 주소) 모듈로 (캐시 내 #Blocks)

<img width="465" alt="스크린샷 2024-06-10 오후 3 45 08" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/8e524267-72da-4fd2-b738-8c30292a415f">

># 태그 및 유효한 비트
## 캐시 위치에 어떤 특정 블록이 저장되어 있는지 어떻게 알 수 있나?
- 블록 주소와 데이터를 저장한다.
- 실제로는 상위 비트만 필요하다.
- 태그를 호출했다.
## 특정 위치에 데이터가 없으면 어떻게 되는가?
- 유효한 비트: 1 = 존재, 0 = 존재하지 않음
- 처음에는 0

># 캐시 예
## 8블록, 1워드/블록, 직접 매핑
## 초기 상태
<img width="492" alt="스크린샷 2024-06-10 오후 3 47 36" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/63ee2364-3814-45c4-b640-6111a5011b29">

<img width="428" alt="스크린샷 2024-06-10 오후 3 48 09" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/af14ed08-355e-4de5-b1f4-505b4389b5a2">

<img width="424" alt="스크린샷 2024-06-10 오후 3 48 23" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/40303546-018d-4ba4-b35a-7ad8cd64ff1a">

<img width="425" alt="스크린샷 2024-06-10 오후 3 48 35" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/9582d304-758d-4cac-a4b4-7f96e88a3c4e">

<img width="422" alt="스크린샷 2024-06-10 오후 3 48 48" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/21e77d61-0b87-4cc8-848e-5c5d6a6b3455">

<img width="427" alt="스크린샷 2024-06-10 오후 3 49 04" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/1913e99f-ef88-4396-a3e1-7635a5850586">

># 주소 세분화
<img width="368" alt="스크린샷 2024-06-10 오후 3 49 54" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/f57b190e-18ec-463e-9d2f-859ba7e841d5">

># 예: 더 큰 블록 크기
## 64개 블록, 16바이트/불록
- 주소 1200은 어떤 블록 번호에 매핑되는가?
## 블록 주소 - ⎣주소/블록크기⎦ = ⎣1200/16⎦ = 75
## 블록 번호 = (블록 주소) modulo (#블록) = 75 modulo 64 = 11
<img width="379" alt="스크린샷 2024-06-10 오후 3 56 51" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/1fe30ef6-4d6f-4cd0-9a97-fdb8231864d7">

># 블록 크기 고려 사항
## 블록이 클수록 미스 비율이 줄어든다.
- 공간적 지역성으로 이냏
## 하지만 고정된 크기의 캐시에서는
- 더 큰 블록 => 더 적은 수

  -> 경쟁 심화 => 미스율 증가

- 더 큰 블록 => 오염

## 미스 페널티가 커짐
- 감소된 미스 비율의 이점을 무시할 수 있다.
- 중요한 단어 우선 및 조기 재시작이 도움을 될 수 있다.

># 캐시 미스
## 캐시 적중 시 CPU는 정상적으로 진행된다.
## 캐시 미스 시
- CPU 파이프라인 정재
- 다음 계층 구조에서 블록을 가져온다.
- 명령어 캐시 미스

  -> 재시작 명령 가져오기

- 데이터 캐시 미스

  -> 완전한 데이터 액세스

># 미스의 원인
## 강제 실패(콜드 스타트 실패라고도 함)
- 블록에 대한 첫 번째 액세스
## 용량 누락
- 제한된 캐시 크기로 인해
- 교체된 블록은 나중에 다시 액세스 된다.
## 충돌 미스
- 완전 연관 캐시가 아닌 경우
- 세트 참가 경쟁으로 인해
- 동일한 전체 크기의 완전 연관 캐시에서는 발생하지 않는다.

># 연속 기입
## 데이터 쓰기 적중 시 캐시의 블록을 업데이트할 수 있다.
- 하지만 그러면 캐시와 메모리가 일치하지 않게 된다.
## Write through: 메모리도 업데이트
## 하지만 쓰기 시간이 더 오래 걸린다.
- 예를 들어 기본 CPI = 1 이면 명령의 10%가 저장되고 메모리에 쓰는 데 100사이클이 걸린다.

  -> 유효 CPI = 1 + 0.1 x 100 = 11

## 해결책: 쓰기 버퍼
- 메모리에 기록되기를 기다리는 데이터를 보관합니다.
- CPU는 즉시 계속된다.

  -> 쓰기 버퍼가 이미 가득 찬 경우에만 쓰기가 중단된다.

># 다시 쓰기
## 대안: 데이터 쓰기 적중 시 캐시의 블록을 업데이트 하기만 하면 된다.
- 각 블록이 더러운지 추적하라.
## 더러운 블록을 고체할 때
- 다시 기억에 적어보아라
- 쓰기 버퍼를 사용하여 '블록 교체'를 먼저 읽을 수 있다.

># 쓰기 할당
## 쓰기 오류가 발생하면 어떻게 되나?
## Write-through의 대안
- 실패 시 할당: 블록을 가져온다.
- Write around: 블럭을 가져오지 않음

  -> 프로그램은 종종 블록을 읽기 전에 전체 블록을 작성하기 때문에 (예: 초기화)

## 후기입인 경우
- 일반적으로 블록을 가져온다.

># 예: Intrinsity FastMATH
## 내장형 MIPS 프로세서
- 12단계 파이프라인
- 각 사이클의 명령 및 데이터 액세스
## 분할 캐시: I-캐시와 D-캐시를 분리
- 각 16KB: 256블록 x 16워드/블록
- D-캐시: 연속 기입 또는 후기입
## SPEC CPU2000 미스 비율
- 아이캐시: 0.4%
- D-캐시: 11.4%
- 가중평균: 3.2%

<img width="556" alt="스크린샷 2024-06-10 오후 4 12 57" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/5aef064c-c09a-4a26-8761-b50257993f38">

># 캐시를 지원하는 메인 메모리
## 주 메모리로 DRAM 사용
- 고정 너비(예: 1워드)
- 고정 폭 믈록 버스로 연결됨

  -> 버스 클럭은 일반적으로 CPU 클럭보다 느립니다.

## 캐시 블록 읽기 예시
- 주소 전송을 위한 1 버스 사이클
- DRAM 액세스당 버스 사이클 15개
- 데이터 전송당 버스 사이클 1개

## 4워드 블록의 경우 1워드 폭 DRAM
- 미스 페널티 = 1 + 4 x 15 + 4 x 1   = 64 사이클
- 대역폭 = 16바이트/65사이클 = 0.25 B/cycle

># 캐시 성능 측정
## CPU 시간의 구성요소
- 프로그램 실행주기

  -> 캐시 적중 시간 포함

- 메모리 정지 주기

  -> ㅈ로 캐시 미스로 인해 발생

## 가정을 단순화 하면 다음과 같다.  
<img width="354" alt="스크린샷 2024-06-10 오후 4 21 53" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/d9b16b72-e93c-4c06-af4b-7252028ab49a">

># 캐시 성능 예
## Given
- I-캐시 실패율 = 2%
- D-캐시 누락률 = 4%
- 미스 페널티 = 100 사이클
- 기본 CPI(이상적인 캐시) = 2
- 로드 및 저장은 명령어의 36%이다.
## 명령어당 미스 사이클
- I-캐시: 0.02 x 100 = 2
- D-캐시: 0.36 x 0.04 x 100 =1.44
## 실제 CPI = 2 + 2 + 1.44 = 5.44
- 이상적인 CPU는 5.44/2 = 2.72배 빠르다.

># 평균 액세스 시간
## 적중 시간도 성능에 중요하다.
## 평균 메모리 액세스 시간(AMAT)
- AMAT = 적중 시간 + 미스 비율 x 미스 페널티
## 예
- 1ns 클록의 CPU, 적중시간 = 1사이클, 미스 페널티 = 20사이클 I-캐시 미스 비율 = 5%
- AMAT = 1 + 0.05 x 20 = 2ns

  -> 명령당 2사이클

># 성능 요약
## CPU 성능이 향상되면
- 미스 페널티가 더욱 중요해진다.
## 기본 CPI 감소
- 메모리 정지에 더 많은 시간이 소요된다.
## 클럭 속도 증가
- 메모리 정지는 더 많은 CPU 주기를 차지한다.
## 시스템 성능을 평가할 때 캐시 동작을 무시할 수 없다.

># 연관 캐시
## 완전 연관
- 특정 블록이 이 모든 캐시 항목에 들어갈 수 있도록 허용
- 모든 항목을 한 번에 검색해야 한다.
- 항목당 비교기(비쌈)
## n방향 집합 연관
- 각 세트에는 n개의 항목이 포함된다.
- 블록 번호는 세트를 결정한다.

  -> (블록 번호) modulo (캐시에 있는 #sets)

- 주어진 세트의 모든 항목을 한 번에 검색
- n개의 비교기(저렴한 비용)

># 연관 캐시 예제
<img width="651" alt="스크린샷 2024-06-10 오후 4 33 16" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/e29d7c40-d953-468f-8dce-65841eda17e3">

># 연관성 스펙트럼
## 8개의 항목이 있는 캐시의 경우
<img width="507" alt="스크린샷 2024-06-10 오후 4 33 54" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/1a7fa255-e838-41d0-a0e1-5d5d0d614763">

># 연관성 예
## 4블록 캐시 비교
- 직접 매핑, 양방향 세트 연관, 완전 연관
- 블록 액세스 순서: 0, 8, 0, 6, 8
## 직접 매핑됨
<img width="561" alt="스크린샷 2024-06-10 오후 4 35 19" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/10c8a3df-08e2-4dac-8b21-23de1fcd86f1">

## 양방향 세트 연관
<img width="561" alt="스크린샷 2024-06-10 오후 4 36 59" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/b17d86f5-fde0-4cc1-a40f-388b6a5f34ae">

## 완전 연관
<img width="557" alt="스크린샷 2024-06-10 오후 4 37 11" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/e8812896-bf74-457f-abaa-d19f0fb537bc">

># 얼마나 많은 연관성이 있나?
## 연관성이 증가하면 미스 비율이 감소한다.
- 하지만 수익이 감소하면서 감소한다.
## SPEC CPU2000 벤치마크에 대한 64KB D 캐시 및 16워드 블록을 갖춘 시스템의 시뮬레이션(미스 비율)
- 단방향(직접 매핑): 10.3%
- 양방향: 8.6%
- 4방향: 8.3%
- 8방향: 8.1%

># 4-Way 세트 연관 캐시 구성
<img width="462" alt="스크린샷 2024-06-10 오후 4 40 23" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/cb9aecd8-4181-46e6-9457-480b2a64fd4d">

># 교체 정책
## 직접 매핑: 선택 사항 없음
## 연관 설정
- 유효하지 않은 항목이 있는 경우 이를 선호한다.
- 그렇지 않으면 세트의 항목 중에서 선택한다.
## 가장 최근에 사용됨(LRU)
- 가장 오랫동안 사용하지 않은 것을 선택하라.

  -> 2-way는 간단하고, 4-way는 관리하기 쉽고, 그 이상은 너무 어렵다.

## 무작위의
- 높은 연관성을 위해 LRU와 거의 동일한 성능 제공

># 다단계 캐시
## CPU에 연결된 기본 캐시
- 작지만 빠르다
## 레벨 2 캐시 서비스가 기본 캐시에서 누락되었다.
- 메인 메모리보다 크고 느리지만 여전히 빠르다.
## 주 메모리 서비스 L-2 캐시가 누락되었다.
## 일부 고급 시스템에는 L-3 캐시가 포함되어 있다.

># 다중 레벨 캐시의 예
## Given
- CPU 기본 CPI = 1, 클록 속도 = 4GHz
- 미스 비율/명령어 = 2%
- 메인 메모리 액세스 시간 = 100ns

## 기본 캐시만 사용
- 미스 페널티 = 100ns/0.25ns = 400 사이클
- 유효 CPI = 1 + 0.02 x 400 = 9

># 다중 레벨 캐시 예(cont'd)
## 이제 L-2 캐시를 추가하시오
- 액세스 시간 = 5ns
- 메인 메모리에 대한 글로벌 미스 비율 = 0.5%
## L-2 히트로 인한 1차 실패
- 페널티 = 5ns/0.25ns = 20사이클
## L-2 미스를 포함한 1차 미스
- 추가 페널티 = 400 사이클
## CPI = 1 + 0.02 x 20 + 0.05 x 400 = 3.4
## 성능 비율 = 9/3.4 = 2.6

># 다중 레벨 캐시 고려사항
## 기본 캐시
- 최소 적중 시간에 집중
## L-2 캐시
- 메인 메모리 액세스를 피하기 위해 낮은 미스 비율에 집중
- 적중 시간은 전체적인 영향이 적다.
## 결과
- L-1 캐시는 일반적으로 작다.
- L-1 블록 크기는 L-2 블록 크기보다 작다.

># 고급 CPU와의 상호 작용
## 순서가 잘못된 CPU는 캐시 누락 중에 명령을 실행할 수 있다.
- 보류 중인 저장소는 로드/저장 단위에 유지된다.
- 예약 스테이션에서 종속 지시 대기

  -> 독립지시 계속

## 누락의 영향은 프로그램 데이터 흐름에 따라 다르다.
- 분석하기가 훨씬 더 어렵다.
- 시스템 시뮬레이션 사용

># 소프트웨어와의 상호 작용
## Miss는 메모리 액세스 패턴에 따라 달라진다.
- 알고리즘 동작
- 메모리 액세스를 위한 컴파일러 최적화

<img width="235" alt="스크린샷 2024-06-10 오후 4 56 28" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/052a6f1e-3a23-4514-9678-0e5cb76dadfd">

># 믿을 수 있음
<img width="1004" alt="스크린샷 2024-06-10 오후 4 57 55" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/63d7c105-09bb-41f6-9db4-4d24ac0f19e9">

># 신뢰성 측정
<img width="481" alt="스크린샷 2024-06-10 오후 4 58 44" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/ad69a349-00f5-42bb-872f-4af05d1d008f">

## 신뢰성: 평균 고장 시간(MTTF)
## 서비스 중단: 평균 수리 시간(MTTR)
## 실패 사이의 평균 시간
- MTBF = MTTF + MTTR
## 가용성 = MTTF / (MTTF + MTTR)
## 가용성 향상
- MTTF 증가: 결함 방지, 결함 허용, 결함 예측
- MTTR 감소: 진단 및 수리를 위한 향상된 도구 및 프로세스

># 9가지 가용성
## 우리는 가용성이 매우 높기를 원한다.
## 한 가지 약어로는 연간 "9개의 가용성" 수를 인용하는 것이다.
## 1년 365일(365 x 24 x 60 = 526,000분)을 가정하면 약식은 다음과 같다.
<img width="418" alt="스크린샷 2024-06-10 오후 5 04 51" src="https://github.com/junhyeok030213/computer-structure/assets/106813806/cfb874ed-d8ba-45a5-baeb-e80413c776f0">

## 오늘날 매우 좋은 인터넷 서비스는 4~5개의 가용성을 제공합니다
- 5 9는 1년에 5분의 수리를 의미하며, 이는 기억 보조 장치입니다.
